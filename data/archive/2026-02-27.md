# ğŸ“° InfoHound - 2026å¹´2æœˆ27æ—¥æ˜ŸæœŸäº”

> ä»Šæ—¥ç²¾é€‰ 2 ç¯‡æ–‡ç« ï¼Œé¢„è®¡é˜…è¯»æ—¶é—´ 3 åˆ†é’Ÿ

---

## ğŸŒŸ å¤´æ¡

### Statement from Dario Amodei on Our Discussions with the Department of War
**æ¥æº**: Hacker News | **è¯„åˆ†**: 7.5/10 ğŸ”´

**ä¸ºä»€ä¹ˆé‡è¦**: This reveals a high-stakes confrontation between a leading AI company and the US military over ethical boundaries, with potential precedent-setting implications for how AI firms navigate national security demands versus democratic values.

**ä¸€å¥è¯æ€»ç»“**: Anthropic's CEO Dario Amodei announces the company is refusing Department of War demands to remove safeguards against mass domestic surveillance and fully autonomous weapons, despite threats of contract termination, 'supply chain risk' designation, and Defense Production Act invocation.

**å…³é”®è¦ç‚¹**:
â€¢ Anthropic was first frontier AI company to deploy in classified US government networks, National Laboratories, and provide custom national security models; Claude is already used for intelligence analysis, modeling/simulation, operational planning, and cyber operations
â€¢ Company previously sacrificed 'several hundred million dollars in revenue' to cut off CCP-linked firms and shut down Chinese state-sponsored cyberattacks using Claude
â€¢ Two non-negotiable exceptions: (1) mass domestic surveillanceâ€”AI can assemble scattered data into comprehensive life profiles at scale, exploiting legal gaps around warrantless data purchases; (2) fully autonomous weaponsâ€”current AI reliability insufficient, risking warfighter and civilian lives, with offered R&D collaboration rejected by DoW
â€¢ DoW threats are contradictory: simultaneously labeling Anthropic a 'supply chain risk' (reserved for US adversaries, unprecedented for American company) while treating Claude as essential enough to invoke Defense Production Act
â€¢ Anthropic will facilitate smooth transition to another provider if offboarded, maintaining models on proposed terms during transition

**èƒŒæ™¯**: Published February 26, 2026, this statement comes amid intensifying US-China AI competition and ongoing policy debates about AI governance, military adoption, and the appropriate role of private companies in setting ethical limits on government use of their technology. The 'Department of War' reference appears to be a deliberate or stylized framing of the Department of Defense.

**æ ‡ç­¾**: AI, AI Safety, National Security, AI Ethics

[é˜…è¯»åŸæ–‡](https://www.anthropic.com/news/statement-department-of-war)


---

## ğŸ”¥ æ·±åº¦æŠ€æœ¯

### ğŸŸ¡ Git in Postgres
**æ¥æº**: Lobste.rs | **è¯„åˆ†**: 7.2/10

**ä¸ºä»€ä¹ˆé‡è¦**: This article proposes a fundamental rearchitecture of how code forges work, replacing the filesystem/git-binary split with a unified Postgres backendâ€”potentially enabling simpler self-hosted deployments that could accelerate the federation and decentralization of open source hosting.

**è¦ç‚¹**:
â€¢ Multiple package managers (Cargo, Homebrew, Go, CocoaPods) hit scaling limits using git as a database, with Homebrew 4.0 switching from git clones to JSON downloads after GitHub explicitly asked them to stop due to repository size.
â€¢ The git data model collapses to just two Postgres tables: objects (content-addressed by SHA1) and refs (named pointers with compare-and-swap updates), implemented in ~2,000 lines of C as libgit2 backends.
â€¢ A practical demo query joins commit messages against Forgejo's issue tracker in a single SQL statementâ€”something that currently requires shelling out to git log and pattern-matching in application code.

[é˜…è¯»åŸæ–‡](https://nesbitt.io/2026/02/26/git-in-postgres.html)


---

## ğŸ“Š ä»Šæ—¥ç»Ÿè®¡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ–‡ç« æ€»æ•° | 2 ç¯‡ |
| å¹³å‡è´¨é‡åˆ† | 7.3/10 |
| é¢„è®¡é˜…è¯»æ—¶é—´ | 3 åˆ†é’Ÿ |

---

*ç”± [InfoHound](https://github.com/Frank-whw/InfoHound) è‡ªåŠ¨ç”Ÿæˆ | AI æ•´ç†ï¼Œäººå·¥é˜…è¯»*
