# ğŸ“° InfoHound - 2026å¹´2æœˆ25æ—¥æ˜ŸæœŸä¸‰

> ä»Šæ—¥ç²¾é€‰ 2 ç¯‡æ–‡ç« ï¼Œé¢„è®¡é˜…è¯»æ—¶é—´ 3 åˆ†é’Ÿ

---

## ğŸŒŸ å¤´æ¡

### Show HN: Moonshine Open-Weights STT models â€“ higher accuracy than WhisperLargev3
**æ¥æº**: Hacker News | **è¯„åˆ†**: 7.8/10 ğŸŸ¡

**ä¸ºä»€ä¹ˆé‡è¦**: Moonshine solves the critical latency and accuracy problems that make Whisper unsuitable for real-time voice applications, offering 5-100x faster inference with better accuracy on everything from MacBooks to Raspberry Pis.

**ä¸€å¥è¯æ€»ç»“**: Moonshine is a new family of open-weights speech-to-text models optimized for live streaming that outperforms Whisper Large V3 in accuracy while running 100x faster on streaming tasks through architectural innovations like flexible input windows and caching.

**å…³é”®è¦ç‚¹**:
â€¢ Achieves 6.65% WER vs Whisper Large V3's 7.44% with 6x fewer parameters (245M vs 1.5B), and delivers 107ms latency on MacBook Pro compared to 11,286ms for Whisper Large V3
â€¢ Eliminates Whisper's 30-second fixed window constraint with flexible input lengths and implements caching for streaming, avoiding redundant computation on previously-seen audio
â€¢ Offers language-specific models (English, Spanish, Mandarin, Japanese, Korean, Vietnamese, Ukrainian, Arabic) that achieve higher accuracy than multilingual models at equivalent sizes
â€¢ Provides unified cross-platform deployment via portable C++ core with native bindings for Python, Swift, Java, and C++ across iOS, Android, macOS, Linux, Windows, and Raspberry Pi
â€¢ Includes batteries-included APIs for transcription, speaker diarization, and semantic command recognition without requiring ML expertise

**èƒŒæ™¯**: Whisper revolutionized open-source STT but was designed for batch processing, not live voice interfaces. Its 30-second fixed window, lack of caching, and poor multilingual accuracy made it impractical for real-time applications. Moonshine was built specifically to address these limitations through architectural redesign rather than incremental optimization.

**æ ‡ç­¾**: Speech-to-Text, Edge AI, Real-time Systems, On-device ML

[é˜…è¯»åŸæ–‡](https://github.com/moonshine-ai/moonshine)


---

## ğŸ”¥ æ·±åº¦æŠ€æœ¯

### ğŸŸ¡ I'm helping my dog vibe code games
**æ¥æº**: Hacker News | **è¯„åˆ†**: 7.1/10

**ä¸ºä»€ä¹ˆé‡è¦**: This demonstrates how creative prompt engineering and automated feedback loops can turn even chaotic input into functional software, offering a blueprint for human-AI collaboration that doesn't require traditional coding skills.

**è¦ç‚¹**:
â€¢ The breakthrough prompt framed Momo's random keystrokes as 'cryptic genius' from an eccentric game designer, enabling Claude to interpret 'y7u8888888ftrg34BC' as a 3D frog bug-catching game called 'Swamp Snacker'
â€¢ Automated feedback toolsâ€”screenshots and simulated gameplay inputâ€”were the single biggest lever for quality, allowing Claude to act as its own QA tester and play through all 6 stages of a game to verify the final boss fight worked
â€¢ Godot 4.6 with C# was chosen over Rust/Bevy (poorer visuals, coordinate confusion) and Unity (MCP bridge instability); Godot's text-based .tscn scene files allowed Claude to read and edit scenes directly

[é˜…è¯»åŸæ–‡](https://www.calebleak.com/posts/dog-game/)


---

## ğŸ“Š ä»Šæ—¥ç»Ÿè®¡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ–‡ç« æ€»æ•° | 2 ç¯‡ |
| å¹³å‡è´¨é‡åˆ† | 7.4/10 |
| é¢„è®¡é˜…è¯»æ—¶é—´ | 3 åˆ†é’Ÿ |

---

*ç”± [InfoHound](https://github.com/Frank-whw/InfoHound) è‡ªåŠ¨ç”Ÿæˆ | AI æ•´ç†ï¼Œäººå·¥é˜…è¯»*
