# AI Provider Configuration
# Supports: anthropic, openai, openrouter, deepseek, custom

# Provider type (default: anthropic)
AI_PROVIDER=anthropic

# API Key (required)
# Anthropic: https://console.anthropic.com/
# OpenAI: https://platform.openai.com/
# OpenRouter: https://openrouter.ai/
AI_API_KEY=your_api_key_here

# Base URL (optional, for custom endpoints or proxy)
# Examples:
#   OpenRouter: https://openrouter.ai/api/v1
#   DeepSeek: https://api.deepseek.com
#   Azure: https://your-resource.openai.azure.com/openai/deployments/your-deployment
#   Custom: https://your-proxy.com/v1
AI_BASE_URL=

# Model name (optional, defaults shown below)
# Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
# OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# OpenRouter: anthropic/claude-3.5-sonnet, openai/gpt-4o
# DeepSeek: deepseek-chat, deepseek-coder
AI_MODEL=claude-3-5-sonnet-20241022

# Max tokens for AI responses (default: 2000)
AI_MAX_TOKENS=2000

# Temperature (0.0-1.0, default: 0.3)
# Lower = more deterministic, Higher = more creative
AI_TEMPERATURE=0.3

# Optional: Debug mode
# DEBUG=true